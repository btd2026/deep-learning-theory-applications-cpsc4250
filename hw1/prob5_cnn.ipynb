{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx34CGiBBnCg"
   },
   "source": [
    "## Problem 5: Convolutional Neural Networks (PyTorch Implementation)\n",
    "\n",
    "Time to implement your first convolutional neural network (CNN) in PyTorch!\n",
    "\n",
    "For this assignment, we'll be training the network on the canonical MNIST dataset. After building the network, we'll experiment with an array of hyperparameters, tweaking the network's width, depth, learning rate and more in pursuit of the highest classification accuracy we can muster.\n",
    "\n",
    "You may find the PyTorch tutorials helpful as you complete this problem: https://pytorch.org/tutorials/beginner/basics/intro.html. If you haven't yet, we suggest you go through them. Pay more attention to the tutorial on the optimization loop, which you will need to build more or less from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meZM-C9IBnCi"
   },
   "source": [
    "### Step 0: Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w64JnesBRc1g"
   },
   "source": [
    "If you haven't set up PyTorch locally, you can do so following this [local installation guide](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "\n",
    "Installing PyTorch locally is **not** necessary for the course. You can access PyTorch either through:\n",
    "\n",
    "- the class partition `cpsc452` on [McCleary](https://docs.ycrc.yale.edu/clusters/mccleary/)\n",
    "\n",
    "- use of [Google Colab](https://colab.research.google.com)\n",
    "\n",
    "If you are new to the Yale High Performance Clusters (HPC) please consulte this [guide](https://docs.ycrc.yale.edu/clusters-at-yale/)\n",
    "<div style=\"display:none\">\n",
    "\n",
    "```bash\n",
    "[mccleary ~]$ salloc ---reservation=cpsc452\n",
    "[cpsc452_netID@gpu ~]$  bash\n",
    "```\n",
    "\n",
    "```bash\n",
    "# sbatch.script\n",
    "@SBATCH -p cpsc452\n",
    "```\n",
    "\n",
    "As usual, we'll start by importing the necessary libraries and setting up our environment. Please run the following cell to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "q8FSpOTjBnCi",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /apps/software/2024a/software/Python/3.12.3-GCCcore-13.3.0/lib/python3.12/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/apps/software/2024a/software/Python/3.12.3-GCCcore-13.3.0/bin/pip'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: pyparsing>=3 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /apps/software/2024a/software/Python/3.12.3-GCCcore-13.3.0/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /apps/software/2024a/software/Python/3.12.3-GCCcore-13.3.0/lib/python3.12/site-packages (from torch) (70.0.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from torch) (2024.6.0)\n",
      "Collecting cuda-bindings==12.9.4 (from torch)\n",
      "  Using cached cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.6.0 (from torch)\n",
      "  Using cached triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch)\n",
      "  Using cached cuda_pathfinder-1.3.4-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/software/2024a/software/Python-bundle-PyPI/2024.06-GCCcore-13.3.0/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
      "Using cached cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
      "Using cached torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached cuda_pathfinder-1.3.4-py3-none-any.whl (30 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, tqdm, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, kiwisolver, fonttools, cycler, cuda-pathfinder, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, cuda-bindings, contourpy, nvidia-cusolver-cu12, matplotlib, torch, torchvision\n",
      "Successfully installed contourpy-1.3.3 cuda-bindings-12.9.4 cuda-pathfinder-1.3.4 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 mpmath-1.3.0 networkx-3.6.1 numpy-2.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 pillow-12.1.1 sympy-1.14.0 torch-2.10.0 torchvision-0.25.0 tqdm-4.67.3 triton-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install --user numpy matplotlib tqdm torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9iNAucyeBnCj",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn            # neural network modules\n",
    "import torch.nn.functional as F  # activation functions\n",
    "import torch.optim as optim      # optimizer\n",
    "import torch.utils.data          # dataloader\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpxqVuOdBnCj",
    "outputId": "fa0e91cd-5468-4696-d736-a67d82c5b1cf"
   },
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "# Load into torch datasets\n",
    "train_dataset = torch.utils.data.TensorDataset(mnist_train.data.unsqueeze(1).float(), mnist_train.targets.long())\n",
    "test_dataset = torch.utils.data.TensorDataset(mnist_test.data.unsqueeze(1).float(), mnist_test.targets.long())\n",
    "\n",
    "# Visualize the data\n",
    "for i in range(100):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.imshow(train_dataset[i][0][0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hScQoMvwBnCk"
   },
   "source": [
    "### Step 1: Learn PyTorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu5fbRkiBnCk"
   },
   "source": [
    "In this section, you will learn different PyTorch basic operations (`Conv2d`, `MaxPool`, `Linear`) and reshape operations. You might refer to PyTorch documentation for details of these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "TOgZDA5XBnCk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Part 1: Explore `nn.Module`\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)  \u001b[38;5;66;03m# image: (1, 1, 28, 28)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# TODO: define a 3x3 convolutional layer that maps 1 input channel to 32 output channels\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# refer to https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# you might need to specify the input channels, output channels, kernel size, stride, padding, etc.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m conv_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv2d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Part 1: Explore `nn.Module`\n",
    "image = torch.randn(1, 1, 28, 28)  # image: (1, 1, 28, 28)\n",
    "\n",
    "\n",
    "# TODO: define a 3x3 convolutional layer that maps 1 input channel to 32 output channels\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "# you might need to specify the input channels, output channels, kernel size, stride, padding, etc.\n",
    "conv_1 = torch.nn.Conv2d(in_channels=1,  out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "output_1 = conv_1(image)    # image: (1, 1, 28, 28) -> output_1: (1, 32, 28, 28)\n",
    "assert output_1.shape == (1, 32, 28, 28), \"The shape of output_1 is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: define a max pooling layer that halves the height and width of the input\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "# you might need to specify the kernel size, stride, padding, etc.\n",
    "pool_1 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "output_2 = pool_1(output_1) # output_1: (1, 32, 28, 28) -> output_2: (1, 32, 14, 14)\n",
    "assert output_2.shape == (1, 32, 14, 14), \"The shape of output_2 is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: define a 3x3 convolutional layer that maps 32 input channels to 64 output channels\n",
    "conv_2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "output_3 = conv_2(output_2) # output_2: (1, 32, 14, 14) -> output_3: (1, 64, 14, 14)\n",
    "assert output_3.shape == (1, 64, 14, 14), \"The shape of output_3 is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: define a max pooling layer that halves the height and width of the input\n",
    "pool_2 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "output_4 = pool_2(output_3) # output_3: (1, 64, 14, 14) -> output_4: (1, 64, 7, 7)\n",
    "assert output_4.shape == (1, 64, 7, 7), \"The shape of output_4 is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: flatten the output of the previous layer\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.flatten.html\n",
    "flatten_4 = torch.flatten(output_4, start_dim=1) # output_4: (1, 64, 7, 7) -> flatten_4: (1, 64 * 7 * 7)\n",
    "assert flatten_4.shape == (1, 64 * 7 * 7), \"The shape of flatten_4 is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: define a linear layer that maps 64 * 7 * 7 input features to 10 output features\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "# you might need to specify the input size, output size, etc.\n",
    "fc = torch.nn.Linear(in_features=64 * 7 * 7, out_features=10)\n",
    "output_5 = fc(flatten_4)     # flatten_4: (1, 64 * 7 * 7) -> output_5: (1, 10)\n",
    "assert output_5.shape == (1, 10), \"The shape of output_5 is incorrect!\"\n",
    "\n",
    "\n",
    "# Part 2: Explore reshape, squeeze, unsqueeze, transpose, repeat\n",
    "tensor = torch.tensor([[[1, 2, 3, 4], [5, 6, 7, 8]]])  # tensor: (1, 2, 4)\n",
    "\n",
    "# TODO: reshape the tensor to (2, 2, 2)\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "reshaped_tensor = torch.reshape(tensor, (2, 2, 2))\n",
    "assert torch.allclose(reshaped_tensor, torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])), \"The reshaped tensor is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: squeeze the first dimension of the tensor\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.squeeze.html\n",
    "squeezed_tensor = torch.squeeze(tensor, dim=0)\n",
    "assert torch.allclose(squeezed_tensor, torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])), \"The squeezed tensor is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: unsqueeze the first dimension of the tensor\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.unsqueeze.html\n",
    "unsqueeze_tensor = torch.unsqueeze(squeezed_tensor, dim=0)\n",
    "assert torch.allclose(unsqueeze_tensor, torch.tensor([[[[1, 2, 3, 4], [5, 6, 7, 8]]]])), \"The unsqueezed tensor is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: transpose dim 1 and dim 2 of the tensor\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.transpose.html\n",
    "transposed_tensor = torch.transpose(tensor, dim0=1, dim1=2)\n",
    "assert torch.allclose(transposed_tensor, torch.tensor([[[1, 5], [2, 6], [3, 7], [4, 8]]])), \"The transposed tensor is incorrect!\"\n",
    "\n",
    "\n",
    "# TODO: repeat the tensor 3 times along dim 0\n",
    "# refer to https://pytorch.org/docs/stable/generated/torch.repeat.html\n",
    "repeated_tensor = tensor.repeat(3, 1, 1)\n",
    "assert torch.allclose(repeated_tensor, torch.tensor([[[1, 2, 3, 4], [5, 6, 7, 8]], [[1, 2, 3, 4], [5, 6, 7, 8]], [[1, 2, 3, 4], [5, 6, 7, 8]]])), \"The repeated tensor is incorrect!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFbDKknpBnCk"
   },
   "source": [
    "### Step 2: Build and Train a SimpleCNN on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1ESojuxBnCk"
   },
   "source": [
    "Follow the TODOs to build a two-layer fully-connected neural network. This is the first ``SimpleCNN`` with linear layers only. You will use this as a baseline model for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJ9kFJ-dBnCk"
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 1,\n",
    "        output_dim: int = 10,\n",
    "        hidden_dim_list: list = [4, 8],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim_list = hidden_dim_list\n",
    "\n",
    "        # TODO: define the layers of the network\n",
    "        self.conv_1 = nn.Linear(28*28, hidden_dim_list[0])\n",
    "        self.conv_2 = nn.Linear(hidden_dim_list[0], hidden_dim_list[1])\n",
    "        self.fc = nn.Linear(hidden_dim_list[1], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)  # flatten the output of the previous layer\n",
    "        \n",
    "        x = self.conv_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzOlanTJBnCl"
   },
   "source": [
    "Implement the training function for your CNN. The function should take the model, optimizer, loss function, training data loader, and validation data loader as input. It should return the training and validation loss and accuracy after each epoch.\n",
    "\n",
    "Implement the ``plot_metrics`` function to visualize the training history.\n",
    "\n",
    "**Warning**: When implementing the training loop, be aware that in each iteration, the `loss` variable is a tensor. It's important to extract its scalar value for logging or calculating average loss. Use `loss.item()` to get the scalar value of the tensor. Otherwise, you might encounter unexpected out-of-memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8eeL3bkBnCl"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(train_metrics, test_metrics, xlabel, ylabel, title):\n",
    "    # TODO: plot train and test metrics in a single plot\n",
    "    plt.plot(train_metrics, label='Train')\n",
    "    plt.plot(test_metrics, label='Test')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "def train(model, loss_fn, train_loader, test_loader, optimizer, epochs=5):\n",
    "    \"\"\"Train the model.\n",
    "    Args:\n",
    "        model: the model\n",
    "        loss_fn: the loss function\n",
    "        train_loader: the training data loader\n",
    "        test_loader: the testing data loader\n",
    "        optimizer: the optimizer\n",
    "        epochs: the number of epochs to train\n",
    "    Returns:\n",
    "        train_losses: the training losses\n",
    "        test_losses: the testing losses\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    loop = tqdm.tqdm(range(1, epochs + 1))\n",
    "\n",
    "    for epoch in loop:\n",
    "        # TODO: implement training and testing loop\n",
    "\n",
    "        # train the model for one epoch\n",
    "        train_loss, train_accuracy = train_epoch(model, loss_fn, train_loader, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # test the model for one epoch\n",
    "        test_loss, test_accuracy = test_epoch(model, loss_fn, test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(train_loss=train_loss, test_loss=test_loss, train_accuracy=train_accuracy, test_accuracy=test_accuracy)\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "\n",
    "def train_epoch(model, loss_fn, train_loader, optimizer):\n",
    "    \"\"\"Train the model for one epoch.\n",
    "    Args:\n",
    "        model: the model\n",
    "        loss_fn: the loss function\n",
    "        train_loader: the training data loader\n",
    "        optimizer: the optimizer\n",
    "    Returns:\n",
    "        train_loss: the loss of the epoch\n",
    "    \"\"\"\n",
    "    model.train()  # set model to training mode\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # TODO: implement training iteration\n",
    "        output = model(data)  # forward pass\n",
    "\n",
    "        loss = loss_fn(output, target)  # compute loss\n",
    "\n",
    "        optimizer.zero_grad()  # zero the gradients\n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # update the parameters\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        perdictons = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        train_accuracy += perdictons.eq(target.view_as(perdictons)).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy /= len(train_loader.dataset)\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def test_epoch(model, loss_fn, test_loader):\n",
    "    \"\"\"Test the model for one epoch.\n",
    "    Args:\n",
    "        model: the model\n",
    "        loss_fn: the loss function\n",
    "        test_loader: the testing data loader\n",
    "    Returns:\n",
    "        test_loss: the loss of the epoch\n",
    "    \"\"\"\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():  # disable gradient calculation\n",
    "        for data, target in test_loader:\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_fn(output, target)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predictions = output.argmax(dim=1, keepdim=True)\n",
    "            test_accuracy += predictions.eq(target.view_as(predictions)).sum().item()\n",
    "    \n",
    "    # Normalize by number of samples\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tjwMsv5BnCl"
   },
   "source": [
    "Use the training function above to train your ``SimpleCNN`` on ``MNIST`` dataset. You should get a training accuracy less than 92%. Don't worry, we will improve it in the next step.\n",
    "\n",
    "Here are some hyperparameters you can try to improve the performance of your model (we will dive into hyperparameter tuning in the last step):\n",
    "- Number of hidden units\n",
    "- Learning rate\n",
    "- Number of training epochs\n",
    "- Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oehm3WU8BnCl"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "input_dim = 1\n",
    "hidden_dim_list = [4, 8]\n",
    "output_dim = 10    # TODO: define the output dimension\n",
    "\n",
    "model = SimpleCNN()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = train(model, loss_fn, train_loader, test_loader, optimizer, epochs=epochs)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plot_metrics(train_losses, test_losses, xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss\")\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_metrics(train_accuracies, test_accuracies, xlabel=\"Epoch\", ylabel=\"Accuracy\", title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKT2uNoiBnCl"
   },
   "source": [
    "### Step 3: Improve the SimpleCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV77o7Z2BnCl"
   },
   "source": [
    "As you can see in the previous step, the training accuracy of the ``SimpleCNN`` is poor. In this step, you will improve the performance of the ``SimpleCNN`` by adding ``nn.MaxPool2d``, ``nn.Dropout``, and activation functions.\n",
    "\n",
    "**Hint**: The max pooling layer is used to downsample the input along the spatial dimensions (width and height) independently for each channel. It is recommended to add the max pooling layer after the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uOKHMiJBnCl"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 1,\n",
    "        output_dim: int = 10,\n",
    "        hidden_dim_list: list = [4, 8],\n",
    "        p: float = 0.0,\n",
    "        act_fn: Callable = F.relu,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim_list = hidden_dim_list\n",
    "\n",
    "        # TODO: define the layers of the network\n",
    "        self.conv_1 = nn.Conv2d(in_channels=input_dim, out_channels=hidden_dim_list[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=hidden_dim_list[0], out_channels=hidden_dim_list[1], kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(hidden_dim_list[1] * 7 * 7, output_dim)\n",
    "        self.act_fn = act_fn\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: add activation functions and dropout to the correct layers\n",
    "        x = self.conv_1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = torch.flatten(x, start_dim=1)  # flatten the output of the previous layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa_UPCqoBnCl"
   },
   "source": [
    "Again, use the training function and the same set of hyperparameters above to train your ``CNN`` on ``MNIST dataset``. You should get a training accuracy around 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50m7mNzUBnCl"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "input_dim = 1\n",
    "hidden_dim_list = [4, 8]\n",
    "output_dim = 10    # TODO: define the output dimension\n",
    "act_fn = F.relu\n",
    "p = 0.0\n",
    "\n",
    "model = CNN()\n",
    "loss_fn = nn.CrossEntropyLoss()  # refer to https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)     # refer to https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # refer to https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)   # refer to https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = train(model, loss_fn, train_loader, test_loader, optimizer, epochs=epochs)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plot_metrics(train_losses, test_losses, xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss\")\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_metrics(train_accuracies, test_accuracies, xlabel=\"Epoch\", ylabel=\"Accuracy\", title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjIfHEA5BnCm"
   },
   "source": [
    "Here are the experiments:\n",
    "- Try adjusting the learning rate to improve its accuracy. You might also try increasing the number of epochs used. Record your results in a table.\n",
    "- Try training your network with different non-linearities between the layers (i.e. relu, softplus, elu, tanh). You should experiment with these and record your test results for each in a table\n",
    "- Try changing the width of the hidden layer, keeping the activation function that performs best. Remember to add these results to your table.\n",
    "- Experiment with the optimizer of your network (i.e. SGD, Adam, RMSProp). You should experiment with these and record your test results for each in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIc0XnDYBnCm"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "input_dim = 1\n",
    "hidden_dim_list = [4, 8]\n",
    "output_dim = 10    # TODO: define the output dimension\n",
    "act_fn = F.relu        # TODO: define the activation function\n",
    "p = 0.5             # TODO: define the dropout probability\n",
    "\n",
    "model = CNN(input_dim=input_dim, output_dim=output_dim, hidden_dim_list=hidden_dim_list, p=p, act_fn=act_fn)\n",
    "loss_fn = nn.CrossEntropyLoss()       # refer to https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)     # refer to https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = train(model, loss_fn, train_loader, test_loader, optimizer, epochs=epochs)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_metrics(train_losses, test_losses, xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_metrics(train_accuracies, test_accuracies, xlabel=\"Epoch\", ylabel=\"Accuracy\", title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJsp0sicBnCm"
   },
   "source": [
    "### Step 4: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XxGZOhABnCm"
   },
   "source": [
    "Now the interesting part begins. Try to improve the performance of your ``CNN`` by tuning the hyperparameters. You should be able to get a training accuracy around 98% and a validation accuracy around 97%.\n",
    "\n",
    "Here are some new parameters you can try to improve the performance of your model:\n",
    "- ``Optimizer (SGD, Adam, RMSProp, etc)``: Different optimizers may lead to different convergence speed and performance.\n",
    "- ``Weight decay (L2 penalty)``: Weight decay is a regularization technique to prevent overfitting. It is recommended to use a small weight decay value (e.g., 1e-4).\n",
    "- ``Activation function (ReLU, Leaky ReLU, Tanh, etc)``: Different activation functions may lead to different convergence speed and performance.\n",
    "- ``Dropout rate``: Dropout is a regularization technique to prevent overfitting. It is recommended to use a small dropout rate (e.g., 0.2).\n",
    "- ...\n",
    "\n",
    "Please implement a grid search algorithm to find the best set of hyperparameters and report the best validation accuracy you can get. Any hyperparameter can be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFcu5EDNBnCm"
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "batch_size = 64\n",
    "learning_rate = [1e-2, 1e-3, 1e-4]\n",
    "epochs = 10\n",
    "input_dim = 1\n",
    "hidden_dim_list = [4, 8]    # to save time, don't tune this\n",
    "output_dim = 10             # TODO: define the output dimension\n",
    "act_fn = [F.relu, F.tanh, F.sigmoid]    # refer to https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "\n",
    "# TODO: and all other hyperparameters you want to tune, e.g., dropout\n",
    "# dropout = [..., ..., ...]\n",
    "# optimizers = [..., ..., ...]   # refer to https://pytorch.org/docs/stable/optim.html\n",
    "dropout = [0.0, 0.5, 0.9]\n",
    "optimizers = [torch.optim.SGD, torch.optim.Adam, torch.optim.RMSprop]\n",
    "loss_fn = nn.CrossEntropyLoss()       # refer to https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_history = None\n",
    "for lr in learning_rate:\n",
    "    for af in act_fn:\n",
    "        print(...)\n",
    "        # TODO: implement the grid search\n",
    "        for p in dropout:\n",
    "            for opt in optimizers:\n",
    "                model = CNN(input_dim=input_dim, output_dim=output_dim, hidden_dim_list=hidden_dim_list, p=p, act_fn=af)\n",
    "                optimizer = opt(model.parameters(), lr=lr)\n",
    "                train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                train_losses, test_losses, train_accuracies, test_accuracies = train(model, loss_fn, train_loader, test_loader, optimizer, epochs=epochs)\n",
    "\n",
    "                if test_accuracies[-1] > best_accuracy:\n",
    "                    best_accuracy = test_accuracies[-1]\n",
    "                    best_model = model\n",
    "                    best_history = (train_losses, test_losses, train_accuracies, test_accuracies)\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best model: {best_model}\")\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_metrics(best_history[0], best_history[1], xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_metrics(best_history[2], best_history[3], xlabel=\"Epoch\", ylabel=\"Accuracy\", title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1TSCHSwBnCm"
   },
   "source": [
    "### Step 5 Confusion Matrix\n",
    "With your best performing model, plot a confusion matrix showing which digits were misclassified, and what they were misclassified as. What numbers are frequently confused with one another by your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWQwO7vzBnCm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = best_model\n",
    "model.eval()  # set model to evaluation mode\n",
    "\n",
    "# TODO: implement the confusion matrix\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():  # disable gradient calculation\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        predictions = output.argmax(dim=1, keepdim=True)\n",
    "        y_true.extend(target.view_as(predictions).cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
